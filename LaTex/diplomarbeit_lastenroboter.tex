\documentclass[ngerman,12pt,a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{fancyhdr}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{nameref}
\usepackage{babel}
\usepackage{hyperref}
\usepackage{titlesec}
\usepackage[a4paper, left=3cm, right=3cm, top=3cm, bottom=3cm]{geometry}
\usepackage{setspace}
\onehalfspacing
\usepackage{mathptmx}
\usepackage{array}
\usepackage{booktabs}
\usepackage{adjustbox}
\usepackage{longtable}
\pagestyle{fancy}
\fancyhf{}
\fancyfoot[R]{\thepage}
\titleformat{\section}{\Huge\bfseries}{\thesection}{1em}{}
\title{\textbf{\Huge Diplomarbeit: \\ Lastenroboter}}
\date{}
\begin{document}
	\maketitle
	\begin{center}
		\textbf{Höhere Technische Bundeslehranstalt Graz Gösting}\\
		\textbf{Schuljahr 2024/25}\\[0.5 cm]
		\includegraphics[scale=0.5]{Pictures/bulme_logo}\\[1 cm]
		\begin{tabular}{l l l}
			\textbf{Diplomanden:} & & \textbf{Betreuer:} \\
			Daniel Schauer & 5AHEL & Prof. DI. Gernot Mörtl \\
			Simon Spari & 5AHEL & \\
			Felix Hochegger & 5AHEL & \\
		\end{tabular}
	\end{center}
	\newpage
	\begin{flushleft}
		\textbf{\Huge Eidesstattliche Erklärung}\\[0.5 cm]
	\end{flushleft}
	Wir erklären an Eides statt, dass wir die vorliegende Diplomarbeit selbstständig und ohne fremde Hilfe verfasst, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt und die den benutzten Quellen wörtlich und inhaltlich entnommenen Stellen als solche erkenntlich gemacht haben. 
	\vspace{2cm}
	
	\noindent
	\begin{tabular}{p{7cm} p{7cm}}
		\hrulefill & \hrulefill \\
		Ort, am TT.MM.JJJJ & Daniel Schauer \\
	\end{tabular}
	
	\vspace{2cm}
	
	\noindent
	\begin{tabular}{p{7cm} p{7cm}}
		& \hrulefill \\
		& Simon Spari \\
	\end{tabular}

	\vspace{2cm}
	\noindent
	\begin{tabular}{p{7cm} p{7cm}}
		& \hrulefill \\
		& Felix Hochegger \\
	\end{tabular}
	\newpage
	\textbf{\Huge Danksagung}\\[0.5 cm]
	An dieser Stelle möchten wir unseren aufrichtigen Dank aussprechen.\\[0.5 cm]
	Ein besonderer Dank gilt Herrn Prof. DI Gernot Mörtl für seine wertvolle Unterstützung, seine fachliche Begleitung und seine konstruktiven Anregungen während der gesamten Arbeit. Seine Expertise und sein Engagement haben maßgeblich zum Gelingen dieser Diplomarbeit beigetragen.\\[0.5 cm]
	Ebenso danken wir unseren Freunden, insbesondere Michael Johannes Anderhuber, für seine Unterstützung beim Schweißen des Gehäuses. Sein handwerkliches Geschick und seine Hilfe waren für die Umsetzung unseres Projekts von großem Wert.\\[0.5 cm]
	Unser großer Dank gilt zudem unserem großzügigen Sponsor,"Vogl Baumarkt Rosental", für das Sponsoring des Metalls für das Gehäuse. Durch diese Unterstützung konnten wir unser Projekt in dieser Form verwirklichen.
	\newpage
	\tableofcontents
	\newpage
	\section{Einleitung}
	\subsection{Kurzzusammenfassung}
	In dieser Diplomarbeit wird ein Lastenroboter entwickelt, der bis zu 25 Kilogramm transportieren kann. Der Roboter wird über eine Website gesteuert, die als Steuerungsplattform dient. Zusätzlich ist eine Kamera eingebaut, die den Transportbereich zeigt, sowie eine Waage, die das Gewicht der transportierten Last misst.\\[0.5 cm]
	Ein Schwerpunkt der Arbeit lieg auf der mechanischen Konstruktion des Roboters, bei der ein stabiles Gehäuse aus Stahl gebaut wird, um Sicherheit und Stabilität zu gewährleisten. Außerdem wird eine eigene Platine entwickelt, die die verschiedenen Hardware-Komponenten, wie die Sensoren und die Motoren, steuert und miteinander verbindet.\\[0.5 cm]
	Die Steuerung des Roboters erfolgt über eine Website, die es dem Benutzer ermöglicht, den Roboter zu bedienen und wichtige Daten wie Akkustand und Gewicht abzurufen. Ein besonderer Fokus liegt auch dabei auf der Übertragung des Kamerabildes auf die Web-Oberfläche sowie der Integration einer schwenkbaren Kamera, um eine flexible Sicht auf den Transportbereich zu gewährleisten. Der ESP32 sorgt dafür, dass die Befehle des Benutzers an den Roboter übermittelt werden.\\[0.5 cm]
	Zusätzlich wird eine OnBoard-Software entwickelt, die es ermöglicht, die Sensoren auszulesen und die Motoren als auch die Kamera anzusteuern.\\[0.5 cm]
	\subsection{Abstract}
	This thesis develops a load robot that can carry up to 25 kilograms. The robot is controlled via a website, which serves as the control platform. Additionally, a camera is integrated to display the transport area, as well as a scale to measure the weight of the carried load.\\[0.5 cm]
	A key focus of the work is on the mechanical design of the robot, where a sturdy steel housing is built to ensure safety and stability. Furthermore, a custom circuit board is developed to control and connect the various hardware components, such as sensors and motors.\\[0.5 cm]
	The robot is controlled via a website, which allows the user to operate the robot and access important data such as battery level and weight. A particular focus is also placed on transferring the camera feed to the web interface and integrating a swivel camera to ensure flexible viewing of the transport area. The ESP32 ensures that the user's commands are transmitted to the robot.\\[0.5 cm]
	Additionally, onboard software is developed to read the sensors and control the motors and camera.
	%Namen links unten als muster für später
	\fancyfoot[L]{Daniel Schauer - nur als Muster}
	\thispagestyle{fancy}
	\newpage
	\section{Projektmanagement}
	
		\subsection{Projektteam} %Daniel
		\begin{center}
		\textbf{Betreuer: Prof. DI. Gernot Mörtl}\\[1cm]
		%Daniel------------------------------
			\begin{minipage}{0.3\textwidth}
				\includegraphics[width=\linewidth]{Pictures/placeholder}
				\captionof{figure}{Porträt \\Daniel Schauer}
				\label{fig:daniel}
			\end{minipage}
			\hfill
			\begin{minipage}{0.65\textwidth}
				\vspace{-10pt}
				\textbf{Daniel Schauer: Software-OnBoard}
				\begin{itemize}
					\item Projektleiter
					\item Verbindung von Software und Hardware (ESP32 zu Sensoren)
					\item Kamera-Übertragung zur Web-Oberfläche
					\item Umsetzung einer schwenkbaren Kamera
					\item Dokumentation
				\end{itemize}
			\end{minipage} \\[0.5 cm]
		
			%Simon---------------------------
			\begin{minipage}{0.3\textwidth}
				\includegraphics[width=\linewidth]{Pictures/placeholder}
				\captionof{figure}{Porträt \\Simon Spari}
				\label{fig:simon}
			\end{minipage}
			\hfill
			\begin{minipage}{0.65\textwidth}
				\vspace{-20pt}
				\textbf{Simon Spari: Software-App}
				\begin{itemize}
					\item Benutzeroberfläche (Web-Oberfläche) für Steuerung
					\item Übertragung der Steuerung/Befehle von Web-Oberfläche zu ESP32
					\item Kamera-Übertragung zur Web-Oberfläche
					\item Dokumentation
				\end{itemize}
			\end{minipage}
			\newpage
			%Felix---------------------------
			\begin{minipage}{0.3\textwidth}
				\includegraphics[width=\linewidth]{Pictures/placeholder}
				\captionof{figure}{Porträt Felix Hochegger}
				\label{fig:felix}
			\end{minipage}
			\hfill
			\begin{minipage}{0.65\textwidth}
				\vspace{-60pt}
				\textbf{Felix Hochegger: Hardware-Design und Mechanik}
				\begin{itemize}
					\item Bau des Roboter Gehäuse
					\item Ansteuerung und Verbindung von Hardware (Ansteuerung und Berechnung der Motoren)
					\item Dokumentation
				\end{itemize}
			\end{minipage}
			\end{center}
			
		\subsection{Projektstrukturplan} %Daniel
		
		\subsection{Meilensteine} %Daniel
		Um unseren Fortschritt und unsere Zeiteinteilung besser im Überblick zu behalten, haben wir uns bestimmte Meilensteine für unser Projekt gesetzt. Diese sind sehr hilfreich, um das Projekt strukturiert umzusetzen, angefangen von der Projektplanung bis hin zum fertigen Prototyp. \\[0.5cm]
		Die folgenden Meilensteine haben wir uns bei der Projektplanung gesetzt:
		\begin{longtable}{| l | l |}
			\hline
			\textbf{Meilenstein} & \textbf{Datum} \\
			\hline
			\endfirsthead
			\hline
			\textbf{Meilenstein} & \textbf{Datum} \\
			\hline
			\endhead
			\hline
			Grundlegendes Gehäuse & 07.11.2024 \\
			\hline
			Funktionsfähige Website & 19.12.2024 \\
			\hline
			Funktionsfähige steuerbare Motoren & 16.01.2025 \\
			\hline
			Funktionsfähiger Prototyp & 06.03.2025 \\
			\hline
		\end{longtable}
		\newpage
		\subsection{Kostenaufstellung} %Daniel
			\begin{center}
				\begin{longtable}{| p{8.2cm} | r | r | r |}
					\hline
					\textbf{Artikel} & \textbf{Einzelpreis} & \textbf{Stückzahl} & \textbf{Gesamt} \\
					\hline
					\endfirsthead
					\hline
					\textbf{Artikel} & \textbf{Einzelpreis} & \textbf{Stückzahl} & \textbf{Gesamt} \\
					\hline
					\endhead
					\hline
					Aufblasbares Rad 10'' 260x85  & 16.70 € & 4 & 66.80 € \\ \hline
					MCP23017 & 4.54 € & 2 & 9.08 € \\ \hline
					PICAA LED Arbeitsscheinwerfer & 6.55 € & 2 & 13.10 € \\ \hline
					2 Stück PWM Motor Steuerung Treiber Platinen & 35.78 € & 2 & 71.56 € \\ \hline
					Micro Servo Motor & 6.04 € & 1 & 6.04 € \\ \hline
					IRM-30-15ST & 17.04 € & 1 & 17.04 € \\ \hline
					SOLSUM 0808 & 25.17 € & 1 & 25.17 € \\ \hline
					Platinen & 37.14 € & 1 & 37.14 € \\ \hline
					ESP32 CAM & 13.70 € & 1 & 13.70 € \\ \hline
					12 Stück Halbbrücken Wägezelle & 11.09 € & 1 & 11.09 € \\ \hline
					ESP32 & 11.09 € & 1 & 11.09 € \\ \hline
					Dunkermotoren & 65.00 € & 2 & 130.00 € \\ \hline
					AGM 12V Batterie & 24.80 € & 1 & 24.80 € \\ \hline
					Diverse Kleinteile & 30.00 € & 1 & 30.00 € \\ \hline
					\textbf{Summe} & & & \textbf{466.61 €} \\
					\hline
				\end{longtable}
			\end{center}
			\newpage
	\section{Antrieb}
	
		\subsection{Motoren} %Felix
		
		\subsection{Motorentreiber} %Felix
		
		\subsection{Schaltungsaufbau} %Felix
		
		\subsection{Code} %Daniel
	
	\section{Webserver} %Spari
	 
		\subsection{Grundlegende Ziele}
	In diesem Kapitel befassen wir uns mit der geplanten Website, die den Benutzern und Benutzerinnen die Steuerung des Lastenroboters ermöglichen soll. Zuallererst definieren wir die grundlegenden Funktionen, die die Website erfüllen soll. Sobald diese erfüllt sind, versuchen wir, das User Interface so einfach und benutzerfreundlich wie möglich zu gestalten. Ein weiterer Punkt ist die Darstellung der spezifischen Messwerte und Daten, damit diese am Webserver schnell und leicht zugänglich sind.\\[0.5cm]
	Für die Entwicklung der Website verwenden wir HTML, CSS und JavaScript, um alle funktionalen und optischen Anforderungen zu erfüllen.  
	
			\subsubsection*{Videoübertragung} 	 
	
	Auf der Website soll eine Echtzeit Videoübertragung der ESP32-CAM angezeigt werden. Die Bildfrequenz und die Qualität der Videoübertragung sollte ausgeglichen sein, so dass in der Übertragung alle Objekte und ggf. Hindernisse frühzeitig erkennbar sind und noch Reaktionszeit zum Manövrieren besteht. 
	
			\subsubsection*{Steuerung}
	
	Auf der Website soll eine grafische Steuereinheit implementiert werden, mit der der Roboter gesteuert und navigiert werden kann. Diese soll dann die entsprechenden Steuerbefehle bzw. Richtungen an den ESP32 senden, wo sie dann in Steuerungsbefehle für die Motoren übersetzt werden.  
	
			\subsubsection*{Anzeigen von Daten}
	
	Auf der Website sollen bestimmte Messwerte und Daten, wie zum Beispiel Akkustand oder zurzeit aufliegende Last, die vom ESP32 durch Sensoren oder Messungen ausgewertet werden, übersichtlich und leicht zugänglich angezeigt werden.
	
		\subsection{Ideen und Entwürfe}
		
		\subsection{Webserver}
		
			\subsubsection{Webserver Setup}
			
	Der Webserver wird mithilfe der Bibliothek ESPAsyncWebServer auf einem ESP32-CAM Mikrocontroller eingerichtet. Diese Bibliothek ermöglicht einen nicht-blockierenden Betrieb, wodurch parallele Anfragen effizient verarbeitet werden können.\footnote{https://github.com/lacamera/ESPAsyncWebServer} \\[0.5cm]
	Für die Netzwerkkonfiguration wurde ein eigener Access Point mit folgenden Parametern definiert:
	
	\begin{itemize}
		\item SSID (Service Set Identifiert) : “Carybot” – dient zur Identifikation des drahtlosen Netwerkes
		\item Passwort: “123456789“ – dient zum Schutz des Netwerkes
		\item Lokale IP-Adresse: 192.168.4.1 – dient zum Zugriff auf die Webserver-Oberfläche
		\item Gateway-Adresse: 192.168.4.1 - ESP32-CAM fungiert als Access Point
		\item Subnetzmaske: 255.255.255.0 - ermöglicht die Kommunikation zwischen Geräten im Bereich 192.168.4.x
	\end{itemize} 
	Der Webserver wird auf Port 80 erstellt. Port 80 ist der Standardport für HTTP-Dienste. 
	\\[0.5cm]
	In der Setup Funktion wird danach überprüft, ob der Access Point erfolgreich konfiguriert worden ist und ob der Access Point erfolgreich gestartet werden kann. Falls ein Fehler auftreten sollte, wird der Setup unterbrochen und die jeweilige Fehlermeldung in der seriellen Konsole ausgegeben. Wenn alles erfolgreich konfiguriert ist und starten kann, wird im Seriellen Monitor die IP-Adresse in der seriellen Konsole ausgegeben. Anschließend wird der Webserver gestartet.
			
			\subsubsection{SPIFFS Setup}
			
	SPIFFS (SPI Flash File System) ist ein leichtgewichtiges Dateisystem für Mikrocontroller mit SPI-Flash-Speicher. Es ermöglicht das Speichern und Verwalten von Dateien direkt im Flash-Speicher des Mikrocontrollers. SPIFFS wird in unserem Projekt benötigt, um statische Dateien für unseren Webserver (HTML-, CSS-, JavaScript Anwendungen) bereitzustellen. \\[0.5cm] 
	In unserem Code wird zuallererst einmal überprüft, ob SPIFFS beim Start der ESP32-CAM richtig initialisiert werden kann. Falls es fehlschlägt, wird eine Fehlermeldung in der seriellen Konsole ausgegeben und das Programm gestoppt. Ansonsten werden die Webserver-Endpunkte über HTTP-GET-Routen definiert, über die unsere statischen Dateien aus SPIFFS an Clients gesendet werden. \\[0.5cm] 
	“/“ ist die Standardroute des Servers. Somit wird dpad.html als Startseite angezeigt, wenn ein Client sich verbindet. \\[0.5cm] 
	“menu-icon.svg“ und “Fernlicht.svg“ werden als SVG-Bilder (Scalable Vector Graphics) an den Browser gesendet. Image/svg+xml sorgt dafür, dass der Browser die Dateien als SVG-Bilder erkennt. \\[0.5cm] 
	“mystyles.css“ wird mit text/css als CSS-Datei gesendet und dient zur Formatierung der Website. \\[0.5cm] 
	“carybot.js“ wird mit application/javascript als Javascript-Datei gesendet und verarbeitet die Eingaben von Clients auf der Website. \\[0.5cm] 
	Wenn alle Dateien erfolgreich geladen sind, wird eine Nachricht in der seriellen Konsole ausgegeben. \\[0.5cm] 
	Die readFile() Funktion wird benötigt, um die jeweiligen Dateien aus SPIFFS lesen zu können. Die Funktion liest eine Datei aus dem SPIFFS-Speicher und gibt den Inhalt als String zurück.
			
	\begin{figure}[h]
		\centering
		\includegraphics{Pictures/SPIFFS\_setup}
		\caption{SPIFFS Initalisierung}
		\label{fig:spiffs_init}
		\par\small Quelle: eigene Abbildung
	\end{figure}	
	
			
		\subsection{WebSocket Kommunikation}
		
			\subsubsection{Kommunikation Setup}	
			
	Für die Kommunikation zwischen dem Webserver und dem ESP32 wird die ArduinoJson und die ArduinoWebSockets Bibliothek benötigt. Die ArduinoJson Bibliothek wird für die Umwandlung der JSON-Steuerbefehle benötigt. Die ArduinoWebSockets Bibliothek wird für die Kommunikation über das WebSocket Protokoll benötigt. \\[0.5cm]
	Für die Netzwerkkonfiguration als Client werden folgenden Parameter definiert:
	\begin{itemize}
		\item SSID: “Carybot“ – gleiche SSID wie ESP32-CAM
		\item Passwort: “123456789“ – gleiches Passwort wie ESP32-CAM
		\item Lokale IP-Adresse: 192.168.4.3 
		\item Gateway-Adresse: 192.168.4.1 – Adresse des Access Points (ESP32-CAM)
		\item Subnetzmaske: 255.255.255.0 – ermöglicht Kommunikation zwischen Geräten im Bereich 192.168.4.x
	\end{itemize}
	Für die WebSocket-Kommunkation wurde der Port 8080 gewählt. \\[0.5cm]
	In der Setup Funktion des Programmes wird dann überprüft, ob die IP-Konfiguration erfolgreich abgeschlossen wurde. Ansonsten kommt es zu einer Fehlermeldung und das Setup wird abgebrochen. Danach wird versucht, sich mit dem WLAN-Netzwerk zu verbinden. Wenn sich der ESP32 erfolgreich mit dem WLAN verbunden hat, wird eine Nachricht und die IP-Adresse des ESP32 in der seriellen Konsole ausgegeben. Danach wird die WebSocket Konfiguration noch gestartet. Es wird definiert, dass die Funktion onWebSocketEvent aufgerufen wird, wenn Events über den WebSocket registriert werden. In der loop Funktion wird dann noch ständig überprüft, ob neue Events am WebSocket registriert werden.
			
			\subsubsection{Message Handling}
			
	In der Funktion onWebSocketEvent() werden die WebSocket-Ereignisse verarbeitet. Sie wird aufgerufen, wenn sich ein WebSocket-Client verbindent, eine Nachricht sendet oder die Verbindung sich trennt.
	Der Parameter num steht für die ID des Clients, der das Event ausgelöst hat. Der Parameter type gibt die Art des WebSocket-Event an. Der Parameter payload sind die empfangenen Daten. Der Parameter length steht für die Größe des payload-Arrays. 
	In der Funktion werden die Events mit einem switch-case verarbeitet\\[0.5cm]
	Übersicht der WebSocket-Ereignisse:
	
	\begin{table}[h]
		\centering
		\renewcommand{\arraystretch}{1.2}
		\setlength{\tabcolsep}{8pt}
		\begin{adjustbox}{max width=\textwidth}
    	\begin{tabular}{|l|p{5cm}|p{6cm}|}

		\hline
		\textbf{Ereignistyp} & \textbf{Beschreibung} & \textbf{Verarbeitung} \\
		\hline
		WStype\_CONNECTED & Ein neuer Client verbindet sich. & Ausgabe der Client-ID \& IP-Adresse in der Konsole \\
		\hline
		WStype\_TEXT & Eine Textnachricht wird empfangen. & Übergabe an \texttt{handleWebSocketMessage()} \\
		\hline
		WStype\_BIN & Binärdaten werden empfangen. & Nachricht in der Konsole (wird nicht verarbeitet) \\
		\hline
		WStype\_DISCONNECTED & Ein Client trennt die Verbindung. & Meldung mit der Client-ID in der Konsole. \\
		\hline
	
		\end{tabular}
		\end{adjustbox}
		\caption{Übersicht der WebSocket-Ereignisse}
		\label{tab:websocket-events}
	\end{table} 
	Die Funktion handleWebSocketMessage() verarbeitet die WebSocket-Nachricht, die als JSON-Objekte gesendet werden. Die Parameter sind wieder die Client-ID, die empfangenen Nachricht und die Länge der empfangenen Nachricht. \\[0.5cm]
	Zuerst wird die empfangene Nachricht (payload) in einen String konvertiert. Diese wird dann in der seriellen Konsole ausgegeben. Danach wird ein JSON-Dokument mit max 200 Bytes erstellt. Die empfangene Nachricht wird dann mit deserialzeJson() geparst. Falls das Parsen erfolgreich war, wird die JSON-Nachricht verarbeitet. \\[0.5cm]
	Wenn die JSON-Nachricht den Namen \texttt{robot\_direction} enthält, wird die Richtung mit der Funktion \texttt{stringToDirection()} in eine eigene Variable umgewandelt. Auch die mitgesendete Variable \texttt{speed} wird ebenfalls in eine eigene Variable gespeichert. \\[0.5cm]
	Wenn die JSON-Nachricht den Namen \texttt{camera\_position} enthält, wird der Wert der Nachricht in die Variable \texttt{camera\_pos} gespeichert und die Funktion \texttt{cam\_turn()}  aufgerufen. \\[0.5cm]
	Wenn die JSON-Nachricht den Namen \texttt{light\_status} enthält, wird der Wert der Nachricht in die boolesche Variable \texttt{light\_status}  gespeichert. Dieser Variable wird dann in die numerische Variable \texttt{light\_st} umgewandelt (1 = an, 0 = aus). Wenn \texttt{light\_st} eine 1 ist, wird die Funktion \texttt{lights\_on(}) aufgerufen, ansonsten wird die Funktion \texttt{lights\_off()} aufgerufen.
			
		\subsection{Kamera}
		
			\subsubsection{Kamera Setup}
			
	Um die Kamera programmieren zu können, muss zunächst das richtige Board \texttt{AI Thinker ESP32-CAM} ausgewählt werden. Danach müssen die ESP32-Kamera-Treiber mit der Bibliothek \texttt{esp\_camera.h} inkludiert werden. Dann muss das passende ESP32-CAM-Modell festgelegt werden. Da wir uns für das \texttt{Ai-Thinker} Modell entschieden haben, muss diese nun definiert werden. Falls ein anderes Modell genutzt wird, muss es entsprechend angepasst werden. \\[0.5cm]
	Als nächstes werden die GPIO-Pins der ESP32-CAM für die Kamera OV2640 konfiguriert. Diese Zuordnung ist spezifisch für das Ai-Thinker-Modell und muss für jedes Modell individuell angepasst werden. \\[0.5cm]
	Als nächstes muss die ESP32-CAM mit der ESP-IDF \texttt{esp\_camera} Bibliothek konfiguriert und initialisiert werden. Als erstes muss mit \texttt{camera\_config\_t} eine Struktur definiert werden, mit der verschiedene Parameter und Eigenschaften wie GPIO-Pins, Bildgröße und Qualität festlegt werden können. \\[0.5cm] 
	LEDC-Kanal und Timer werden für das Taktsignal benötigt, um die Kamera zu betreiben.
		
			\subsection{Videoübertragung}
			
	In unserem Projekt werden die Live-Bilder per WebSocket an den Webserver gesendet. Um dies umzusetzen, wird zuerst eine Webserver-Route benötigt. Dazu wird eine http-GET-Anfrage für die Hauptseite (“/“) definiert. Im Code wird ein JavaScript Skript benutzt, um eine Websocket-Verbindung herzustellen. Die IP-Adresse wird automatisch durch \texttt{windows.location.hostname} erkannt. Port 81 wird für das WebSocket-Streaming verwendet. Wenn die ESP32-CAM ein neues Bild als WebSocket-Nachricht versendet, wird es als JPEG-Blob gespeichert. Danach wird ein temporär URL-Link erstellt. Das Bild wird schlussendlich in einem \texttt{<img>}-Tag mit der id \texttt{stream} angezeigt. \\[0.5cm]
	Die WebSocket Verbindung wird die ganze Zeit überwacht. In der Konsole wird ausgegeben, wenn die Websocket-Verbindung aktiv ist. Falls die Verbindung abbrechen sollte, wird nach 5 Sekunden automatisch ein erneuter Verbindungsversuch gestartet. Zum Schluss wird der HTML-Code mit \texttt{HTTP-Status 200} (OK) an den Browser gesendet. 
	
			
		\subsection{Website}

			\subsubsection{Implementierung der Steuerung}
			
				\subsubsection*{Steuerkreuz}
				
	Um den Roboter überhaupt steuern zu können, wird ein Steuerkreuz implementiert. Das Steuerkreuz befindet sich mittig am rechten Bildschirmrand. Das Steuerkreuz besteht aus fünf Tasten, nämlich: Vorwarts (\texttt{UP}), (\texttt{DOWN} ), links (\texttt{LEFT}), rechts (\texttt{RIGHT}) und in der Mitte Stop (\texttt{HALT}). \\[0.5cm]
	Im HTML-Code wird das Steuerkreuz als HTML div tag im body Bereich definiert. Für die Formatierung wird die CSS-Klasse \texttt{dpad-container} verwendet. Die einzelnen Richtungstasten des Steuerkreuze werden auch als HTML div tags definiert. Jede Taste wird mit der CSS-Klasse \texttt{button} und der jeweiligen Zusatzklasse \texttt{up/down/left/right/center} formatiert. Beim jeweiligen Tastendruck wird außerdem immer das Attribut \texttt{data-direction} mit der jeweiligen Richtung belegt.\\[0.5cm]
	Die CSS-Klasse \texttt{dpad-container } ist das übergeordnete Element, welches die Steuerkreuztasten enthalten. Es wird als CSS Grid mit einer 3x3 Struktur definiert. Es gibt Lücken (.) an den Ecken, damit das Layout wie ein Steuerkreuz aussieht. Der Abstand zwischen den Tasten wird mit 10px festgelegt. Der Container hat eine feste Breite von 120px und ist vertikal so wie horizontal zentriert. \\[0.5cm]
	Die CSS-Klasse \texttt{button} sorgt für eine einheitliche Gestaltung der Tasten des Steuerkreuzes. Jede Taste hat eine Größe von 60x60px. Eine Flexbox wird verwendet, um die Tasten jeweils mittig in den einzelnen Positionen des Grids zu positionieren. Jede Taste hat einen dunkelgrauen Hintergrund, eine weiße Textfarbe, einen 2px dicken dunklen Rahmen und abgerundete Ecken. Die Optionen \texttt{-webkit-tap-highlight-color: transparent} und \texttt{user-select: none} sorgen dafür, dass auf mobilen Geräten der Text in den Tasten nicht blau markiert werden kann, damit die Steuerung nicht blockiert wird. \\[0.5cm]
	Die fünf Richtungsklassen sorgen dafür, dass die Tasten des Steuerkreuzes in den zuvor definierten Grid-Bereichen zugewiesen und richtig platziert werden. Die mittlere Taste bekommt außerdem eine leicht hellere Farbe zugewiesen, um ihn optisch von den anderen abzuheben. \\[0.5cm]
	Außerdem bekommen alle Tasten einen Hover-Effekt, damit sie etwas heller werden, wenn eine Taste gedrückt wird. \\[0.5cm]
	Im JavaScript-Code sorgen zwei EventListener dafür, dass die Elemente auf der Seite nicht ziehbar und verschiebbar sind und dass das Rechtsklick-Menü nicht geöffnet werden kann. Diese Maßnahmen verhindern unerwünschte Benutzerinteraktionen und sorgen für eine reibungslose Bedienung. \\[0.5cm]
	Vier weitere EventListener kümmern sich um die Eingabe des Steuerkreuzes. Es wird zuerst jeder \texttt{mousedown} (Linksklick) bzw. ein \texttt{touchstart} (klick auf mobile Geräte) abgefangen. Danach wird überprüft, ob das geklickte Element innerhalb eines \texttt{.button} Elements (Steuerkreuztaste) liegt. Falls ja, wird die Richtung aus dem data-direction-Attribut gelesen und an die \texttt{send()} Funktion übergeben. Wenn ein \texttt{mouseup} (Maus loslassen) oder ein \texttt{touchend} (Finger loslassen) abgefangen wird, wird die Funktion \texttt{stop()} aufgerufen. \\[0.5cm]
	Die JavaScript Funktion \texttt{send()} kümmert sich um das Senden der Steuerungsbefehle. Zuerst wird überprüft, ob die aktuelle Richtung nicht bereits die gewünschte Richtung ist. Falls ja, wird ein JSON-Objekt erstellt, welche die Richtung sowie die Geschwindigkeit enthält. Zu debug-Zwecken wird die Richtung sowie die Geschwindigkeit in der Webkonsole ausgegeben. Danach wird überprüft, ob die WebSocket-Verbindung zur ESP32-CAM offen ist. Wenn ja, wird die Nachricht auch für debug-Zwecken an die ESP32-CAM gesendet, ansonsten wird eine Fehlermeldung ausgegeben. Dasselbe geschieht für die WebSocket-Verbindung zum ESP32. Dort werden jedoch die Steuerbefehle weiterverarbeitet. \\[0.5cm]
	Die JavaScript Funktion \texttt{stop()} sorgt dafür, dass der Roboter anhält, wenn eine Taste des Steuerkreuzes losgelassen wird. Zuerst wird überprüft, ob die aktuelle Richtung nicht bereits \texttt{HALT} ist, ansonsten wird sie daraufgesetzt. Danach wird ein Stopp-Befehl als JSON-Nachricht vorbereitet. Zu debug-Zwecken wird wieder ein halt in der Webkonsole ausgegeben. Danach wird der Stopp-Befehl wieder an die WebSocket-Verbindung zur ESP32-CAM für debug-Zwecke gesendet. Danach wird sie auch an die WebSocket-Verbindung zum ESP32 gesendet, wo dieser weiterverarbeitet wird. \\[0.5cm]
	
				
				\subsubsection*{Geschwindigkeitseinstellung}
			
	Um die Fortbewegungsgeschwindigkeit des Roboters kontrollieren zu können, gibt es auf der linken Seite neben dem Steuerkreuz einen vertikalen Geschwindigkeitsslider, mit der die Geschwindigkeit der Motoren gesteuert werden kann. Wenn der Slider nach oben gezogen wird, beschleunigt der Roboter, wenn der Slider nach unten gezogen wird, wird die Geschwindigkeit verlangsamt. \\[0.5cm]
	Im HTML-Code wird mit der CSS-Klasse \texttt{slider-container} ein Bereich im Hauptbereich definiert. Der Slider wird als HTML \texttt{<input>}-Tag mit dem type \texttt{range} von 0 bis 100 definiert. Für das Design wird die CSS-Klasse \texttt{slider} verwendet und beim Verschieben des Sliders wird die JavaScript Funktion \texttt{speed\_change()} mit der aktuellen Position des Sliders aufgerufen. \\[0.5cm]
	In der CSS-Klasse \texttt{slider-container} wird ein Bereich mit der Größe 50x220 Pixel definiert, in dem der Slider angezeigt werden soll. In \texttt{slider} wird definiert, dass der Slider vertikal und nicht horizontal angezeigt wird. Außerdem wird die Richtung auf \texttt{Right to Left} gesetzt, damit die aktuelle Position richtig erhöht bzw. vermindert bei Auf- und Niederschieben des Sliders wird. \\[0.5cm]
	Im JavaScript-Code wird die aktuelle Position des Sliders in die eigene Variable \texttt{speed} gespeichert. Die Geschwindigkeit wird immer bei einem Steuerbefehl des Steuerkreuzes mitübertragen. (siehe Steuerung)
				
				\subsubsection*{Kamerasteuerung}
				
	Um mit der Videoübertragung besser Objekte und Hindernisse zu erkennen, ist die Kamera leicht schwenkbar. Um nun die Kamera auf unserer Website bewegen zu können, gibt es auf der linken Seite einen horizontalen Slider, mit der die Kamera ein Stück links und rechts geschwenkt werden kann. \\[0.5cm]
	Im HTML-Code wird ein mit der CSS-Klasse \texttt{camera-container} ein Bereich im Hauptbereich definiert. Der Slider wird als HTML \texttt{<input>}-Tag mit dem type \texttt{range} von 0 bis 180 definiert. Für das Design wird die CSS-Klasse \texttt{cam\_slider} verwendet und beim Verschieben des Sliders wird die JavaScript Funktion \texttt{camera\_change()} mit der aktuellen Position des Sliders aufgerufen. \\[0.5cm]
	In der CSS-Klasse \texttt{camera-container} wird ein Bereich erstellt, in dem der Slider angezeigt werden soll.  In \texttt{cam\_slider} wird die Slidespur mit einer Breite von 150 Pixel und einer Höhe von 10 Pixel definiert. Der Hintergrund ist hellgrau und die Ecken werden leicht abgerundet.  In \texttt{webkit-slider-thumb} wird der Sliderknopf mit 20x20 Pixel definiert. Der Hintergrund ist dunkelgrau mit einem 2px breiten, dunkleren Rand. \\[0.5cm]
	Im JavaScript-Code wird die aktuelle Position des Sliders verarbeitet. Dazu wird die Position in eine JSON-Nachricht gespeichert. Zu debug-Zwecken wird die Position noch in der Website Konsole ausgegeben. Wenn der WebSocket Verbindung zum ESP32 offen ist, wird die aktuelle Position übermittelt. \\[0.5cm]
			
			\subsubsection{Echtzeit-Videoanzeige}
			
	Die Videoübertragung dient dazu, den Roboter über größere Entfernungen autonom steuern zu können. Mit der Videoübertragung werden Objekte und Hindernisse erkennbar und kann diese somit ausweichen. \\[0.5cm]
	Die Videoübertragung wird über der ganzen Website im Hintergrund angezeigt. \\[0.5cm]
	Im HTML-Code wird die Videoübertragung als HTML \texttt{<img>}-Tag mit der id \texttt{dynamicimage} im Hauptbereich definiert. \\[0.5cm]
	Im CSS-Code wird nun das Element mit der id \texttt{dynamicimage} formatiert. Es wird definiert, dass die Größe 100\% der Breite sowie 100\% der Höhe einnimmt. Die Position wird dabei auf absolut gesetzt. \\[0.5cm]
	Im JavaScript-Code wird die WebSocket-Verbindung zur ESP32-CAM gehandelt. In der Funktion \texttt{connectWebSocket\_cam()} wird zuerst ein WebSocket mit der eigenen IP-Adresse erstellt (da Webserver auf ESP32-CAM gehostet wird) und dem Port 81 erstellt. Wenn nun eine Nachricht auf der WebSockte-Verbindung ankommt (siehe Videoübertragung ESP32-CAM) wird diese extrahiert. Das mitgesendete BLOB wird in einem neuem BLOB als jpeg-Bild gespeichert. Danach wird eine URL (Adresse) erstellt, die zu diesem BLOB führt. Dann wird eine Variable für die Videoübertragung im HTML \texttt{<img>}-Tag erstellt. Die Source dieses Bildes wird dann mit dem neuen, erhaltenen Bild ersetzt. Da die ESP32-CAM die ganze Zeit neue Blobs sendet, wird das Bild die ganze Zeit ersetzt, was dazu führt, dass es aussieht, als wäre es ein Video. \\[0.5cm]
	Wenn sich die ESP32-CAM verbindet, wird zu Debug-Zwecken eine Nachricht in der Webkonsole ausgegeben. \\[0.5cm]
	Wenn die Verbindung zur ESP32-CAM verloren geht, wird wieder zu Debug-Zwecke eine Nachricht in der Webkonsole ausgegeben und ein neuer Verbindungsversuch wird nach 5 Sekunden gestartet. \\[0.5cm]
	
	
			
			\subsubsection{Anzeige von Sensordaten und Verbindungsstatus}
			
				\subsubsection*{Sensordaten}	
			
	In der linken oberen Ecke der Website befindet sich das Menü-icon. Ein Klick darauf ruft die Sidebar für die Daten auf. Die Sidebar klappt sich am linken Bildschirmrand auf. Darin kann ist der aktuelle Akkustand sowie das aktuelle aufliegende Gewicht auslesbar. Um das Menü wieder schließen zu können, ist ein erneuter Klick auf das Icon erforderlich und die Sidebar wird wieder zugeklappt. \\[0.5cm]		
	Im HTML-Code wird im Body-Bereich wird das Icon als HTML \texttt{<img>}-Tag eingefügt. Als Quelle wird die im SPIFFS hochgeladene Grafik \texttt{menu-icon.svg} Grafik verwendet. Für das Design wird die CSS-Klasse \texttt{menu-icon} verwendet und beim onclick Event wird die JavaScript Funktion \texttt{togglemenu()} aufgerufen. \\[0.5cm]
	Im HTML \texttt{<div>}-Tag werden die einzelnen Daten festgelegt und mir der CSS-Klasse \texttt{mymenu} formatiert. Das Gewicht und der Akkustand werden als HTML \texttt{<p>}-Tag angezeigt und mit der CSS-Klasse \texttt{daten} formatiert. \\[0.5cm]
	In der CSS-Klasse \texttt{mymenu} wird die sidebar formatiert. Das Menü ist fixiert und nimmt 100\% der Höhe ein. Die Anfängliche ist 0, da es versteckt bzw. eingeklappt ist. Die Hintergrundfarbe ist schwarz und es befindet sich auf der z-Ebene 1 um den Hauptinhalt überdecken zu können. Beim Ein- und Ausblenden dauert 0.5 Sekunden, um einen sanften Übergang zu ermöglichen. \\[0.5cm]
	Der Hautinhalt \texttt{\#main} hat eine Animation, damit er beim Öffnen des Menüs nach rechts verschoben werden kann. \\[0.5cm]
	Falls der Bildschirm kleiner als 450px Höhe hat, werden die Abstände der angezeigten Daten verkleinert. Das dient dazu, um besonders auf Handys die Ansicht zu optimieren. \\[0.5cm]
	Die CSS-Klasse \texttt{menu-icon} positioniert das Icon in der linken oberen Ecke mit einer 30x30px Format. \texttt{Cursor: pointer} sorgt dafür, dass das Icon anklickbar ist. \\[0.5cm]
	Die CSS-Klasse \texttt{daten} formatiert die einzelnen Daten im Menü. Sie werden in der Schriftart Arial, Helvetica oder sans-serif angezeigt und in der Farbe Weiß, mit der Schriftgröße 1.2em (20\% größer) mittig angezeigt. \\[0.5cm]
	In der JavaScript Funktion \texttt{connectWebSocket\_carybot()} wird im \texttt{onmessage()}-event die übertragenen Daten verarbeitet. Für debug-Zwecken werden die angekommen Daten in der WebKonsole ausgegeben. Danach werden die JSON-Nachrichten extrahiert. Wenn die Nachricht den Akkustand beinhaltet, wird dieser im HTML \texttt{<p>}-Tag mit der id \texttt{Akkustand} im Menü angezeigt. Wenn die Nachricht das Gewicht beinhaltet, wird dieses im HTML \texttt{<p>}-Tag mit der id \texttt{Gewicht} im Menü angezeigt. Falls beim Umwandeln ein Fehler auftreten sollte, wird dieser in der Webkonsole ausgegeben. \\[0.5cm]
	
				\subsubsection*{Verbindungsstatus}
	
	In der WebSocket Status-Box wird der aktuelle Verbindungszustand zum ESP32 angezeigt. Wenn keine Verbindung vorhanden ist, ist die Box rot. Wenn die Verbindung erfolgt, wird die Box grün. \\[0.5cm]
	Im HTML-Code wird die Status-Box als HTML \texttt{<span>}-Tag definiert. Für das Design wird die CSS-Klasse \texttt{status-box} kombiniert je nach Verbindungsstatus mit der Klasse \texttt{connected} oder \texttt{disconnected}. \\[0.5cm]
	In der CSS-Klasse \texttt{status-box} wird die grundlegende Box am linken oberen Bildschirmrand positioniert. Die Box liegt auf der zweiten z-Ebene. Die Schrift wird weiß definiert und wird fett dargestellt. Wenn eine Verbindung hergestellt wurde, wird der Hintergrund auf grün festgelegt (\texttt{status-box.connected}), ansonsten ist der Hintergrund rot (\texttt{status-box.disconnected}). \\[0.5cm]
	Im JavaScript-Code werden die \texttt{onopen()} und \texttt{onclose()} Events der WebSocket Verbindung gehandelt. Bei einem Verbindungsaufbau (\texttt{onopen()}) wird die Status-Box grün und der Text wechselt zu \texttt{Connected}. Außerdem wird eine Nachricht für Debug-Zwecke ausgegeben. Bei einem Verbindungsabbruch wird die Status-Box wieder rot und der Text wechselt zu \texttt{Disconnected}. Es wird automatisch alle 5 Sekunden ein neuer Versuch zur Verbindungsaufbau gestartet.
			
		\subsection{Herausforderungen und Optimierungen}
		
			\subsubsection{Probleme bei der WebSocket Kommunikation}
			
			\subsubsection{Latenz- und Performance Optimierungen}
			
			\subsubsection{(Speicher- und Rechenleistungseinschränkungen des ESP32)}
		\newpage
					
		\subsection{(Fazit und Ausblick)}
		
			\subsubsection{(Mögliche Erweiterungen und Verbesserungen)}
	
	\section{Gehäuse}
	
		\subsection{Planung und Design} %Felix
		
		\subsection{Realisierung} %Felix
	
		\subsection{Materialliste} %Felix
	
	\section{Platine}
	
		\subsection{Grundschaltung} %Felix
		
		\subsection{Circuit Board} %Felix
		
		\subsection{Fertiger Prototyp} %Felix
	
	
	\section{Kamera}
	
		\subsection{Kamera im Überblick} %Daniel
		
		\subsection{Videoübertragung} %Simon
		
		\subsection{Kameraschwenkung} %Felix
		
			\subsubsection{Gehäuse} %Felix
			
			\subsubsection{Servomotor} %Daniel
	
		\subsection{Code} %Daniel und %Simon
		
\newpage
	\section{Sensoren}
	
		\subsection{Abstandsensor} %Daniel
		
		\subsection{Gewichtsmessung}
		
			\subsubsection{Grundprinzip} %Daniel
		
			\subsubsection{Schaltungsaufbau} %Daniel
		
			\subsubsection{Code} %Daniel
	
	
	\section{Entwicklungstools}
	
	 \subsection{Autodesk Fushion}
	 
	 \subsection{Eagle}
	 	 
	 \subsection{VS-Code}
	 
	 Visual Studio Code (VS-Code) ist eine kostenlose IDE (integrated development environment) entwickelt von Microsoft. VS-Code funktioniert auch auf anderen Betriebssystemen wie zum Beispiel Windows, Linux oder macOS. VS-Code unterstützt einen Großteil der Programmiersprachen und kann durch Extentions mit vielen nützlichen Features und Sprachen immer wieder erweitert werden.\footnote{https://code.visualstudio.com/}
	 	
	 	\subsubsection{Setup}
	 	
	 Um ein Projekt in VS-Code erstellen zu können, müssen einige Schritte befolgt werden. Zuallererst muss die IDE von https://code.visualstudio.com/ für das jeweilig passende Betriebssystem heruntergeladen und installiert werden. Um Mikrocontroller wie ESPs oder Arduinos in VS-Code programmieren zu können, wird die PlatformIO IDE Extension benötigt. Um die PlatformIO IDE Extension in VS-Code zu installieren, drückt man einfach auf das Extensions Symbol oder drückt die Tastenkombination Ctrl+Shift+X um das Extensions Menü zu öffnen. Danach gibt man in der Suchleiste “PlatformIO IDE“ ein und wählt die Extension mit der Ameise als Icon. Dann drückt man auf “Install“ und wartet, bis die Extension fertig heruntergeladen ist. Nach der Installation sollte das PlatformIO Icon (Ameisenkopf) auf der linken Seite unter dem Extension Menü erscheinen. \\[0.5cm]
	 Um nun ein neues Projekt zu erstellen, klickt man auf das PlatformIO Icon und wählt “+ New Project“. \\[0.5cm]
	 Im Project Wizard wählt man nun den gewünschten Namen, das Board, das Framework als auch den Speicherungsort des Projektes. Bei unserem Projekt wählten wir das Board “Espressif ESP32 Dev Module“ und als Framework “Arduino“, da wir einen EPS32 zum Programmieren verwendeten. \\[0.5cm]
	 	
	 	
	 	\subsubsection{Bibliotheken}
	 	
	 Bibliotheken sind ein weiterer wichtiger Bestandteil für das Programmieren. Bibliotheken beinhalten bereits eine Sammlung von vorgefertigtem Code, der für bestimmte Aufgaben, wie zum Beispiel zum Auswerten eines Sensors, verwendet werden kann. Bibliotheken werden verwendet, um den Code zu minimieren und dadurch die Lesbarkeit sowie die Effizienz zu steigern. Um eine Bibliothek für PlatformIO in VS-Code zu installieren, muss das PIO Home Menü geöffnet werden. Darin befindet sich der Reiter „Libraries“. Wenn dieses geöffnet wird, erscheint eine Suchleiste, mit der die gewünschten Bibliotheken zum Projekt hinzugefügt werden können.
	 
		\subsubsection{verwendete Bibliotheken}
		
			\subsubsection*{ESPAsyncWebServer}
			
	Die ESPAsnycWebServer Bibliothek ermöglicht es, Webanwendungen effizient und mit hoher Performance auf ESP8266- und ESP32 Mikrocontroller zu hosten. Der Asynchrone Betrieb verhindert Blockierungen und sorgt für eine flüssige Verarbeitung mehrere Anfragen gleichzeitig. Außerdem unterstützt die Bibliothek WebSockets, welche für die Echtzeitkommunikation zwischen Client und Server benötigt wurden. Die Bibliothek ist eine leistungsfähigere Alternative zur klassischen WebServer-Bibliothek, da sie ressourcenschonender und nicht blockieren arbeitet.\footnote{https://github.com/lacamera/ESPAsyncWebServer}
	
			\subsubsection*{ArduinoJSON}
			
	Die ArduinoJson Bibliothek ermöglicht die Verarbeitung von JSON-String in Objekte und umgekehrt. Sie ist speziell für Geräte mit begrenztem Speicher und Rechenleistung optimiert. Die Bibliothek wird benötigt, um die erhaltenen Steuerbefehle am ESp32 zu konvertieren und um sie anschließend weiterzuverarbeiten.\footnote{https://arduinojson.org/}
			
			\subsubsection*{HCSR04}
			
			\subsubsection*{arduinoWebSockets}
			
	Die WebSockets Bibliothek ermöglicht eine Kommunikation über das WebSocket Protokoll für Arduino-Boards, ESP8266 und ESP32. Die Bibliothek wird für die Echtzeit-Kommunikation zwischen dem Webserver und den ESP32 benötigt. Außerdem werden die Bilder der ESp32-CAM über einen WebSocket an den Webserver gesendet. Die Bibliothek ist eine großartige Ergänzung zur ESPAsyncWebServer Bibliothek.\footnote{https://github.com/Links2004/arduinoWebSockets}
			
			\subsubsection*{ESp32Servo}
			
			\subsubsection*{Adafruit\_MCP23x17}
			
			\subsubsection*{HX711\_ADC}
				
	 \subsection{LaTex}
	 
	 \subsection{GitHub}
	
	\section{Abbildungsverzeichnis}
	
		\listoffigures
	
	\section{Literaturverzeichnis}
	 
\end{document}