      Diplomarbeit:
      Lastenroboter

Höhere Technische Bundeslehranstalt Graz Gösting
                     Schuljahr 2024/25

Diplomanden:     5AHEL  Betreuer:
Daniel Schauer   5AHEL  Prof. DI. Gernot Mörtl
Simon Spari      5AHEL
Felix Hochegger

                 1
Eidesstattliche Erklärung

Wir erklären an Eides statt, dass wir die vorliegende Diplomarbeit selbstständig und ohne
fremde Hilfe verfasst, keine anderen als die angegebenen Quellen und Hilfsmittel benutzt
und die den benutzten Quellen wörtlich und inhaltlich entnommenen Stellen als solche
erkenntlich gemacht haben.

Ort, am TT.MM.JJJJ  Daniel Schauer

                    Simon Spari

                    Felix Hochegger

                                     2
  Danksagung

An dieser Stelle möchten wir unseren aufrichtigen Dank aussprechen.
Ein besonderer Dank gilt Herrn Prof. DI Gernot Mörtl für seine wertvolle Unterstützung,
seine fachliche Begleitung und seine konstruktiven Anregungen während der gesamten
Arbeit. Seine Expertise und sein Engagement haben maßgeblich zum Gelingen dieser
Diplomarbeit beigetragen.
Ebenso danken wir unseren Freunden, insbesondere Michael Johannes Anderhuber, für
seine Unterstützung beim Schweißen des Gehäuses. Sein handwerkliches Geschick und
seine Hilfe waren für die Umsetzung unseres Projekts von großem Wert.
Unser großer Dank gilt zudem unserem großzügigen Sponsor,"Vogl Baumarkt Rosental",
für das Sponsoring des Metalls für das Gehäuse. Durch diese Unterstützung konnten wir
unser Projekt in dieser Form verwirklichen.

                                                                                                          3
Inhaltsverzeichnis

1 Einleitung         7

1.1 Kurzzusammenfassung . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

1.2 Abstract . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7

2 Projektmanagement  9

2.1 Projektteam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9

2.2 Projektstrukturplan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.3 Meilensteine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10

2.4 Kostenaufstellung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

3 Antrieb            12

3.1 Motoren . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3.2 Motorentreiber . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3.3 Schaltungsaufbau . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

3.4 Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

4 Webserver          12

4.1 Grundlegende Ziele . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12

4.2 Ideen und Entwürfe . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

4.3 Webserver . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13

4.3.1 Webserver Setup . . . . . . . . . . . . . . . . . . . . . . . . . . 13

4.3.2 SPIFFS Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

4.4 WebSocket Kommunikation . . . . . . . . . . . . . . . . . . . . . . . . 14

4.4.1 Kommunikation Setup . . . . . . . . . . . . . . . . . . . . . . . 14

4.4.2 Message Handling . . . . . . . . . . . . . . . . . . . . . . . . . 15

4.5 Kamera . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

4.5.1 Kamera Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

4.6 Videoübertragung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

4.7 Website . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

4.7.1 Implementierung der Steuerung . . . . . . . . . . . . . . . . . . 18

4.7.2 Echtzeit-Videoanzeige . . . . . . . . . . . . . . . . . . . . . . . 18

4.7.3 Anzeige von Sensordaten und Systemstatus . . . . . . . . . . . . 15

4.8 Herausforderungen und Optimierungen . . . . . . . . . . . . . . . . . . 15

4.8.1 Probleme bei der WebSocket Kommunikation . . . . . . . . . . . 15

4.8.2 Latenz- und Performance Optimierungen . . . . . . . . . . . . . 15

                     4
      4.8.3 (Speicher- und Rechenleistungseinschränkungen des ESP32) . . . 15
4.9 (Fazit und Ausblick) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

      4.9.1 (Mögliche Erweiterungen und Verbesserungen) . . . . . . . . . . 16

5 Gehäuse            16

5.1 Planung und Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

5.2 Realisierung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

5.3 Materialliste . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

6 Platine            16

6.1 Grundschaltung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

6.2 Circuit Board . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

6.3 Fertiger Prototyp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7 Kamera             16

7.1 Kamera im Überblick . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7.2 Videoübertragung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7.3 Kameraschwenkung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7.3.1 Gehäuse . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7.3.2 Servomotor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

7.4 Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16

8 Sensoren           17

8.1 Abstandsensor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

8.2 Gewichtsmessung . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

8.2.1 Grundprinzip . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

8.2.2 Schaltungsaufbau . . . . . . . . . . . . . . . . . . . . . . . . . . 17

8.2.3 Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

9 Entwicklungstools  17

9.1 Autodesk Fushion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

9.2 Eagle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

9.3 VS-Code . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

9.3.1 Setup . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

9.3.2 Bibliotheken . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

9.3.3 verwendete Bibliotheken . . . . . . . . . . . . . . . . . . . . . . 18

9.4 LaTex . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

9.5 GitHub . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19

                     5
10 Abbildungsverzeichnis  19

11 Literaturverzeichnis   19

                          6
1 Einleitung

1.1 Kurzzusammenfassung

In dieser Diplomarbeit wird ein Lastenroboter entwickelt, der bis zu 25 Kilogramm trans-
portieren kann. Der Roboter wird über eine Website gesteuert, die als Steuerungsplatt-
form dient. Zusätzlich ist eine Kamera eingebaut, die den Transportbereich zeigt, sowie
eine Waage, die das Gewicht der transportierten Last misst.

Ein Schwerpunkt der Arbeit lieg auf der mechanischen Konstruktion des Roboters, bei
der ein stabiles Gehäuse aus Stahl gebaut wird, um Sicherheit und Stabilität zu gewähr-
leisten. Außerdem wird eine eigene Platine entwickelt, die die verschiedenen Hardware-
Komponenten, wie die Sensoren und die Motoren, steuert und miteinander verbindet.

Die Steuerung des Roboters erfolgt über eine Website, die es dem Benutzer ermöglicht,
den Roboter zu bedienen und wichtige Daten wie Akkustand und Gewicht abzurufen. Ein
besonderer Fokus liegt auch dabei auf der Übertragung des Kamerabildes auf die Web-
Oberfläche sowie der Integration einer schwenkbaren Kamera, um eine flexible Sicht auf
den Transportbereich zu gewährleisten. Der ESP32 sorgt dafür, dass die Befehle des Be-
nutzers an den Roboter übermittelt werden.

Zusätzlich wird eine OnBoard-Software entwickelt, die es ermöglicht, die Sensoren aus-
zulesen und die Motoren als auch die Kamera anzusteuern.

1.2 Abstract

This thesis develops a load robot that can carry up to 25 kilograms. The robot is controlled
via a website, which serves as the control platform. Additionally, a camera is integrated
to display the transport area, as well as a scale to measure the weight of the carried load.

A key focus of the work is on the mechanical design of the robot, where a sturdy steel
housing is built to ensure safety and stability. Furthermore, a custom circuit board is de-
veloped to control and connect the various hardware components, such as sensors and
motors.

The robot is controlled via a website, which allows the user to operate the robot and ac-
cess important data such as battery level and weight. A particular focus is also placed on

Daniel Schauer - nur als Muster  7
transferring the camera feed to the web interface and integrating a swivel camera to en-
sure flexible viewing of the transport area. The ESP32 ensures that the user’s commands
are transmitted to the robot.

Additionally, onboard software is developed to read the sensors and control the motors
and camera.

Daniel Schauer - nur als Muster  8
2 Projektmanagement

2.1 Projektteam

                                Betreuer: Prof. DI. Gernot Mörtl

Abbildung 1: Porträt  Daniel Schauer: Software-OnBoard
Daniel Schauer            • Projektleiter
                          • Verbindung von Software und Hardware (ESP32 zu
Abbildung 2: Porträt         Sensoren)
Simon Spari               • Kamera-Übertragung zur Web-Oberfläche
                          • Umsetzung einer schwenkbaren Kamera
                          • Dokumentation

                      Simon Spari: Software-App
                          • Benutzeroberfläche (Web-Oberfläche) für Steue-
                             rung
                          • Übertragung der Steuerung/Befehle von Web-
                             Oberfläche zu ESP32
                          • Kamera-Übertragung zur Web-Oberfläche
                          • Dokumentation

Daniel Schauer - nur als Muster                                   9
                            Felix Hochegger: Hardware-Design und Mechanik
                                • Bau des Roboter Gehäuse
                                • Ansteuerung und Verbindung von Hardware (An-
                                   steuerung und Berechnung der Motoren)
                                • Dokumentation

Abbildung 3: Porträt Felix
Hochegger

2.2 Projektstrukturplan

2.3 Meilensteine

Um unseren Fortschritt und unsere Zeiteinteilung besser im Überblick zu behalten, haben
wir uns bestimmte Meilensteine für unser Projekt gesetzt. Diese sind sehr hilfreich, um
das Projekt strukturiert umzusetzen, angefangen von der Projektplanung bis hin zum fer-
tigen Prototyp.

Die folgenden Meilensteine haben wir uns bei der Projektplanung gesetzt:

Meilenstein                      Datum

Grundlegendes Gehäuse            07.11.2024

Funktionsfähige Website          19.12.2024

Funktionsfähige steuerbare Motoren 16.01.2025

Funktionsfähiger Prototyp        06.03.2025

Daniel Schauer - nur als Muster                                           10
2.4 Kostenaufstellung

Artikel                          Einzelpreis Stückzahl Gesamt

Aufblasbares Rad 10” 260x85      16.70 C              4 66.80 C

MCP23017                         4.54 C               2 9.08 C

PICAA LED Arbeitsscheinwerfer    6.55 C               2 13.10 C

2 Stück PWM Motor Steuerung Treiber Platinen 35.78 C  2 71.56 C

Micro Servo Motor                6.04 C               1 6.04 C

IRM-30-15ST                      17.04 C              1 17.04 C

SOLSUM 0808                      25.17 C              1 25.17 C

Platinen                         37.14 C              1 37.14 C

ESP32 CAM                        13.70 C              1 13.70 C

12 Stück Halbbrücken Wägezelle   11.09 C              1 11.09 C

ESP32                            11.09 C              1 11.09 C

Dunkermotoren                    65.00 C              2 130.00 C

AGM 12V Batterie                 24.80 C              1 24.80 C

Diverse Kleinteile               30.00 C              1 30.00 C

Summe                                                 466.61 C

Daniel Schauer - nur als Muster                       11
3 Antrieb

3.1 Motoren
3.2 Motorentreiber
3.3 Schaltungsaufbau
3.4 Code

4 Webserver

4.1 Grundlegende Ziele

In diesem Kapitel befassen wir uns mit der geplanten Website, die den Benutzern und
Benutzerinnen die Steuerung des Lastenroboters ermöglichen soll. Zuallererst definieren
wir die grundlegenden Funktionen, die die Website erfüllen soll. Sobald diese erfüllt sind,
versuchen wir, das User Interface so einfach und benutzerfreundlich wie möglich zu ge-
stalten. Ein weiterer Punkt ist die Darstellung der spezifischen Messwerte und Daten,
damit diese am Webserver schnell und leicht zugänglich sind.

Für die Entwicklung der Website verwenden wir HTML, CSS und JavaScript, um alle
funktionalen und optischen Anforderungen zu erfüllen.

Videoübertragung
Auf der Website soll eine Echtzeit Videoübertragung der ESP32-CAM angezeigt werden.
Die Bildfrequenz und die Qualität der Videoübertragung sollte ausgeglichen sein, so dass
in der Übertragung alle Objekte und ggf. Hindernisse frühzeitig erkennbar sind und noch
Reaktionszeit zum Manövrieren besteht.

Steuerung
Auf der Website soll eine grafische Steuereinheit implementiert werden, mit der der Ro-
boter gesteuert und navigiert werden kann. Diese soll dann die entsprechenden Steuerbe-
fehle bzw. Richtungen an den ESP32 senden, wo sie dann in Steuerungsbefehle für die
Motoren übersetzt werden.

Daniel Schauer - nur als Muster  12
Anzeigen von Daten
Auf der Website sollen bestimmte Messwerte und Daten, wie zum Beispiel Akkustand
oder zurzeit aufliegende Last, die vom ESP32 durch Sensoren oder Messungen ausgewer-
tet werden, übersichtlich und leicht zugänglich angezeigt werden.

4.2 Ideen und Entwürfe

4.3 Webserver

4.3.1 Webserver Setup
Der Webserver wird mithilfe der Bibliothek ESPAsyncWebServer auf einem ESP32-CAM
Mikrocontroller eingerichtet. Diese Bibliothek ermöglicht einen nicht-blockierenden Be-
trieb, wodurch parallele Anfragen effizient verarbeitet werden können.1

Für die Netzwerkkonfiguration wurde ein eigener Access Point mit folgenden Parametern
definiert:

    • SSID (Service Set Identifiert) : “Carybot” – dient zur Identifikation des drahtlosen
       Netwerkes

    • Passwort: “123456789“ – dient zum Schutz des Netwerkes

    • Lokale IP-Adresse: 192.168.4.1 – dient zum Zugriff auf die Webserver-Oberfläche

    • Gateway-Adresse: 192.168.4.1 - ESP32-CAM fungiert als Access Point

    • Subnetzmaske: 255.255.255.0 - ermöglicht die Kommunikation zwischen Geräten
       im Bereich 192.168.4.x

Der Webserver wird auf Port 80 erstellt. Port 80 ist der Standardport für HTTP-Dienste.

In der Setup Funktion wird danach überprüft, ob der Access Point erfolgreich konfiguriert
worden ist und ob der Access Point erfolgreich gestartet werden kann. Falls ein Fehler
auftreten sollte, wird der Setup unterbrochen und die jeweilige Fehlermeldung in der seri-
ellen Konsole ausgegeben. Wenn alles erfolgreich konfiguriert ist und starten kann, wird
im Seriellen Monitor die IP-Adresse in der seriellen Konsole ausgegeben. Anschließend
wird der Webserver gestartet.

    1https://github.com/lacamera/ESPAsyncWebServer

Daniel Schauer - nur als Muster  13
4.3.2 SPIFFS Setup
SPIFFS (SPI Flash File System) ist ein leichtgewichtiges Dateisystem für Mikrocontroller
mit SPI-Flash-Speicher. Es ermöglicht das Speichern und Verwalten von Dateien direkt
im Flash-Speicher des Mikrocontrollers. SPIFFS wird in unserem Projekt benötigt, um
statische Dateien für unseren Webserver (HTML-, CSS-, JavaScript Anwendungen) be-
reitzustellen.

In unserem Code wird zuallererst einmal überprüft, ob SPIFFS beim Start der ESP32-
CAM richtig initialisiert werden kann. Falls es fehlschlägt, wird eine Fehlermeldung in
der seriellen Konsole ausgegeben und das Programm gestoppt. Ansonsten werden die
Webserver-Endpunkte über HTTP-GET-Routen definiert, über die unsere statischen Da-
teien aus SPIFFS an Clients gesendet werden.

“/“ ist die Standardroute des Servers. Somit wird dpad.html als Startseite angezeigt, wenn
ein Client sich verbindet.

“menu-icon.svg“ und “Fernlicht.svg“ werden als SVG-Bilder (Scalable Vector Graphics)
an den Browser gesendet. Image/svg+xml sorgt dafür, dass der Browser die Dateien als
SVG-Bilder erkennt.

“mystyles.css“ wird mit text/css als CSS-Datei gesendet und dient zur Formatierung der
Website.

“carybot.js“ wird mit application/javascript als Javascript-Datei gesendet und verarbeitet
die Eingaben von Clients auf der Website.

Wenn alle Dateien erfolgreich geladen sind, wird eine Nachricht in der seriellen Konsole
ausgegeben.

Die readFile() Funktion wird benötigt, um die jeweiligen Dateien aus SPIFFS lesen zu
können. Die Funktion liest eine Datei aus dem SPIFFS-Speicher und gibt den Inhalt als
String zurück.

4.4 WebSocket Kommunikation

4.4.1 Kommunikation Setup
Für die Kommunikation zwischen dem Webserver und dem ESP32 wird die ArduinoJson
und die ArduinoWebSockets Bibliothek benötigt. Die ArduinoJson Bibliothek wird für

Daniel Schauer - nur als Muster  14
die Umwandlung der JSON-Steuerbefehle benötigt. Die ArduinoWebSockets Bibliothek
wird für die Kommunikation über das WebSocket Protokoll benötigt.

Für die Netzwerkkonfiguration als Client werden folgenden Parameter definiert:

    • SSID: “Carybot“ – gleiche SSID wie ESP32-CAM

    • Passwort: “123456789“ – gleiches Passwort wie ESP32-CAM

    • Lokale IP-Adresse: 192.168.4.3

    • Gateway-Adresse: 192.168.4.1 – Adresse des Access Points (ESP32-CAM)

    • Subnetzmaske: 255.255.255.0 – ermöglicht Kommunikation zwischen Geräten im
       Bereich 192.168.4.x

Für die WebSocket-Kommunkation wurde der Port 8080 gewählt.

In der Setup Funktion des Programmes wird dann überprüft, ob die IP-Konfiguration er-
folgreich abgeschlossen wurde. Ansonsten kommt es zu einer Fehlermeldung und das
Setup wird abgebrochen. Danach wird versucht, sich mit dem WLAN-Netzwerk zu ver-
binden. Wenn sich der ESP32 erfolgreich mit dem WLAN verbunden hat, wird eine Nach-
richt und die IP-Adresse des ESP32 in der seriellen Konsole ausgegeben. Danach wird
die WebSocket Konfiguration noch gestartet. Es wird definiert, dass die Funktion onWeb-
SocketEvent aufgerufen wird, wenn Events über den WebSocket registriert werden. In der
loop Funktion wird dann noch ständig überprüft, ob neue Events am WebSocket registriert
werden.

4.4.2 Message Handling

In der Funktion onWebSocketEvent() werden die WebSocket-Ereignisse verarbeitet. Sie
wird aufgerufen, wenn sich ein WebSocket-Client verbindent, eine Nachricht sendet oder
die Verbindung sich trennt. Der Parameter num steht für die ID des Clients, der das Event
ausgelöst hat. Der Parameter type gibt die Art des WebSocket-Event an. Der Parame-
ter payload sind die empfangenen Daten. Der Parameter length steht für die Größe des
payload-Arrays. In der Funktion werden die Events mit einem switch-case verarbeitet

Übersicht der WebSocket-Ereignisse:
    Die Funktion handleWebSocketMessage() verarbeitet die WebSocket-Nachricht, die

als JSON-Objekte gesendet werden. Die Parameter sind wieder die Client-ID, die emp-
fangenen Nachricht und die Länge der empfangenen Nachricht.

Daniel Schauer - nur als Muster  15
Ereignistyp          Beschreibung                   Verarbeitung
WStype_CONNECTED
WStype_TEXT          Ein neuer Client verbindet     Ausgabe der Client-ID & IP-
WStype_BIN           sich.                          Adresse in der Konsole
WStype_DISCONNECTED
                     Eine Textnachricht wird emp-   Übergabe                  an
                     fangen.
                                                    handleWebSocketMessage()
                     Binärdaten werden empfan-
                     gen.                           Nachricht in der Konsole (wird
                                                    nicht verarbeitet)
                     Ein Client trennt die Verbin-
                     dung.                          Meldung mit der Client-ID in der
                                                    Konsole.

Tabelle 3: Übersicht der WebSocket-Ereignisse

Zuerst wird die empfangene Nachricht (payload) in einen String konvertiert. Diese wird
dann in der seriellen Konsole ausgegeben. Danach wird ein JSON-Dokument mit max
200 Bytes erstellt. Die empfangene Nachricht wird dann mit deserialzeJson() geparst.
Falls das Parsen erfolgreich war, wird die JSON-Nachricht verarbeitet.

Wenn die JSON-Nachricht den Namen robot_direction enthält, wird die Richtung mit
der Funktion stringToDirection() in eine eigene Variable umgewandelt. Auch die
mitgesendete Variable speed wird ebenfalls in eine eigene Variable gespeichert.

Wenn die JSON-Nachricht den Namen camera_position enthält, wird der Wert der
Nachricht in die Variable camera_pos gespeichert und die Funktion cam_turn() auf-
gerufen.

Wenn die JSON-Nachricht den Namen light_status enthält, wird der Wert der Nach-
richt in die boolesche Variable light_status gespeichert. Dieser Variable wird dann in
die numerische Variable light_st umgewandelt (1 = an, 0 = aus). Wenn light_st eine 1
ist, wird die Funktion lights_on() aufgerufen, ansonsten wird die Funktion lights_off()
aufgerufen.

4.5 Kamera

4.5.1 Kamera Setup

Um die Kamera programmieren zu können, muss zunächst das richtige Board AI Thinker
ESP32-CAM ausgewählt werden. Danach müssen die ESP32-Kamera-Treiber mit der Bi-
bliothek esp_camera.h inkludiert werden. Dann muss das passende ESP32-CAM-Modell
festgelegt werden. Da wir uns für das Ai-Thinker Modell entschieden haben, muss diese
nun definiert werden. Falls ein anderes Modell genutzt wird, muss es entsprechend ange-
passt werden.

Daniel Schauer - nur als Muster                                               16
Als nächstes werden die GPIO-Pins der ESP32-CAM für die Kamera OV2640 konfi-
guriert. Diese Zuordnung ist spezifisch für das Ai-Thinker-Modell und muss für jedes
Modell individuell angepasst werden.

Als nächstes muss die ESP32-CAM mit der ESP-IDF esp_camera Bibliothek konfigu-
riert und initialisiert werden. Als erstes muss mit camera_config_t eine Struktur defi-
niert werden, mit der verschiedene Parameter und Eigenschaften wie GPIO-Pins, Bild-
größe und Qualität festlegt werden können.

LEDC-Kanal und Timer werden für das Taktsignal benötigt, um die Kamera zu betreiben.

4.6 Videoübertragung

In unserem Projekt werden die Live-Bilder per WebSocket an den Webserver gesen-
det. Um dies umzusetzen, wird zuerst eine Webserver-Route benötigt. Dazu wird ei-
ne http-GET-Anfrage für die Hauptseite (“/“) definiert. Im Code wird ein JavaScript
Skript benutzt, um eine Websocket-Verbindung herzustellen. Die IP-Adresse wird auto-
matisch durch windows.location.hostname erkannt. Port 81 wird für das WebSocket-
Streaming verwendet. Wenn die ESP32-CAM ein neues Bild als WebSocket-Nachricht
versendet, wird es als JPEG-Blob gespeichert. Danach wird ein temporär URL-Link er-
stellt. Das Bild wird schlussendlich in einem <img>-Tag mit der id stream angezeigt.

Die WebSocket Verbindung wird die ganze Zeit überwacht. In der Konsole wird ausge-
geben, wenn die Websocket-Verbindung aktiv ist. Falls die Verbindung abbrechen soll-
te, wird nach 5 Sekunden automatisch ein erneuter Verbindungsversuch gestartet. Zum
Schluss wird der HTML-Code mit HTTP-Status 200 (OK) an den Browser gesendet.

Daniel Schauer - nur als Muster  17
4.7 Website

4.7.1 Implementierung der Steuerung

Steuerkreuz

Um den Roboter überhaupt steuern zu können, wird ein Steuerkreuz implementiert. Das
Steuerkreuz befindet sich mittig am rechten Bildschirmrand. Das Steuerkreuz besteht aus
fünf Tasten, nämlich: Vorwarts (UP), (DOWN ), links (LEFT), rechts (RIGHT) und in der Mit-
te Stop (HALT).

Im HTML-Code wird das Steuerkreuz als HTML div tag im body Bereich definiert. Für
die Formatierung wird die CSS-Klasse dpad-container verwendet. Die einzelnen Rich-
tungstasten des Steuerkreuze werden auch als HTML div tags definiert. Jede Taste wird

Daniel Schauer - nur als Muster  15
mit der CSS-Klasse button und der jeweiligen Zusatzklasse up/down/left/right/center
formatiert. Beim jeweiligen Tastendruck wird außerdem immer das Attribut data-direction
mit der jeweiligen Richtung belegt.

Die CSS-Klasse dpad-container ist das übergeordnete Element, welches die Steu-
erkreuztasten enthalten. Es wird als CSS Grid mit einer 3x3 Struktur definiert. Es gibt
Lücken (.) an den Ecken, damit das Layout wie ein Steuerkreuz aussieht. Der Abstand
zwischen den Tasten wird mit 10px festgelegt. Der Container hat eine feste Breite von
120px und ist vertikal so wie horizontal zentriert.

Die CSS-Klasse button sorgt für eine einheitliche Gestaltung der Tasten des Steuerkreu-
zes. Jede Taste hat eine Größe von 60x60px. Eine Flexbox wird verwendet, um die Tasten
jeweils mittig in den einzelnen Positionen des Grids zu positionieren. Jede Taste hat einen
dunkelgrauen Hintergrund, eine weiße Textfarbe, einen 2px dicken dunklen Rahmen und
abgerundete Ecken. Die Optionen -webkit-tap-highlight-color: transparent und
user-select: none sorgen dafür, dass auf mobilen Geräten der Text in den Tasten nicht
blau markiert werden kann, damit die Steuerung nicht blockiert wird.

Die fünf Richtungsklassen sorgen dafür, dass die Tasten des Steuerkreuzes in den zuvor
definierten Grid-Bereichen zugewiesen und richtig platziert werden. Die mittlere Taste
bekommt außerdem eine leicht hellere Farbe zugewiesen, um ihn optisch von den ande-
ren abzuheben.

Außerdem bekommen alle Tasten einen Hover-Effekt, damit sie etwas heller werden,
wenn eine Taste gedrückt wird.

Im JavaScript-Code sorgen zwei EventListener dafür, dass die Elemente auf der Seite
nicht ziehbar und verschiebbar sind und dass das Rechtsklick-Menü nicht geöffnet wer-
den kann. Diese Maßnahmen verhindern unerwünschte Benutzerinteraktionen und sorgen
für eine reibungslose Bedienung.

Vier weitere EventListener kümmern sich um die Eingabe des Steuerkreuzes. Es wird
zuerst jeder mousedown (Linksklick) bzw. ein touchstart (klick auf mobile Geräte) ab-
gefangen. Danach wird überprüft, ob das geklickte Element innerhalb eines .button Ele-
ments (Steuerkreuztaste) liegt. Falls ja, wird die Richtung aus dem data-direction-Attribut
gelesen und an die send() Funktion übergeben. Wenn ein mouseup (Maus loslassen) oder
ein touchend (Finger loslassen) abgefangen wird, wird die Funktion stop() aufgerufen.

Die JavaScript Funktion send() kümmert sich um das Senden der Steuerungsbefehle.

Daniel Schauer - nur als Muster  16
Zuerst wird überprüft, ob die aktuelle Richtung nicht bereits die gewünschte Richtung ist.
Falls ja, wird ein JSON-Objekt erstellt, welche die Richtung sowie die Geschwindigkeit
enthält. Zu debug-Zwecken wird die Richtung sowie die Geschwindigkeit in der Web-
konsole ausgegeben. Danach wird überprüft, ob die WebSocket-Verbindung zur ESP32-
CAM offen ist. Wenn ja, wird die Nachricht auch für debug-Zwecken an die ESP32-
CAM gesendet, ansonsten wird eine Fehlermeldung ausgegeben. Dasselbe geschieht für
die WebSocket-Verbindung zum ESP32. Dort werden jedoch die Steuerbefehle weiterver-
arbeitet.

Die JavaScript Funktion stop() sorgt dafür, dass der Roboter anhält, wenn eine Tas-
te des Steuerkreuzes losgelassen wird. Zuerst wird überprüft, ob die aktuelle Richtung
nicht bereits HALT ist, ansonsten wird sie daraufgesetzt. Danach wird ein Stopp-Befehl
als JSON-Nachricht vorbereitet. Zu debug-Zwecken wird wieder ein halt in der Webkon-
sole ausgegeben. Danach wird der Stopp-Befehl wieder an die WebSocket-Verbindung
zur ESP32-CAM für debug-Zwecke gesendet. Danach wird sie auch an die WebSocket-
Verbindung zum ESP32 gesendet, wo dieser weiterverarbeitet wird.

Geschwindigkeitseinstellung

Um die Fortbewegungsgeschwindigkeit des Roboters kontrollieren zu können, gibt es auf
der linken Seite neben dem Steuerkreuz einen vertikalen Geschwindigkeitsslider, mit der
die Geschwindigkeit der Motoren gesteuert werden kann. Wenn der Slider nach oben ge-
zogen wird, beschleunigt der Roboter, wenn der Slider nach unten gezogen wird, wird die
Geschwindigkeit verlangsamt.

Im HTML-Code wird mit der CSS-Klasse slider-container ein Bereich im Hauptbe-
reich definiert. Der Slider wird als HTML <input>-Tag mit dem type range von 0 bis
100 definiert. Für das Design wird die CSS-Klasse slider verwendet und beim Verschie-
ben des Sliders wird die JavaScript Funktion speed_change() mit der aktuellen Position
des Sliders aufgerufen.

In der CSS-Klasse slider-container wird ein Bereich mit der Größe 50x220 Pixel de-
finiert, in dem der Slider angezeigt werden soll. In slider wird definiert, dass der Slider
vertikal und nicht horizontal angezeigt wird. Außerdem wird die Richtung auf Right to
Left gesetzt, damit die aktuelle Position richtig erhöht bzw. vermindert bei Auf- und Nie-
derschieben des Sliders wird.

Daniel Schauer - nur als Muster  17
Im JavaScript-Code wird die aktuelle Position des Sliders in die eigene Variable speed
gespeichert. Die Geschwindigkeit wird immer bei einem Steuerbefehl des Steuerkreuzes
mitübertragen. (siehe Steuerung)

Kamerasteuerung

Um mit der Videoübertragung besser Objekte und Hindernisse zu erkennen, ist die Ka-
mera leicht schwenkbar. Um nun die Kamera auf unserer Website bewegen zu können,
gibt es auf der linken Seite einen horizontalen Slider, mit der die Kamera ein Stück links
und rechts geschwenkt werden kann.

Im HTML-Code wird ein mit der CSS-Klasse camera-container ein Bereich im Haupt-
bereich definiert. Der Slider wird als HTML <input>-Tag mit dem type range von 0 bis
180 definiert. Für das Design wird die CSS-Klasse cam_slider verwendet und beim Ver-
schieben des Sliders wird die JavaScript Funktion camera_change() mit der aktuellen
Position des Sliders aufgerufen.

In der CSS-Klasse camera-container wird ein Bereich erstellt, in dem der Slider an-
gezeigt werden soll. In cam_slider wird die Slidespur mit einer Breite von 150 Pixel
und einer Höhe von 10 Pixel definiert. Der Hintergrund ist hellgrau und die Ecken wer-
den leicht abgerundet. In webkit-slider-thumb wird der Sliderknopf mit 20x20 Pixel
definiert. Der Hintergrund ist dunkelgrau mit einem 2px breiten, dunkleren Rand.

Im JavaScript-Code wird die aktuelle Position des Sliders verarbeitet. Dazu wird die Po-
sition in eine JSON-Nachricht gespeichert. Zu debug-Zwecken wird die Position noch in
der Website Konsole ausgegeben. Wenn der WebSocket Verbindung zum ESP32 offen ist,
wird die aktuelle Position übermittelt.

4.7.2 Echtzeit-Videoanzeige
Die Videoübertragung dient dazu, den Roboter über größere Entfernungen autonom steu-
ern zu können. Mit der Videoübertragung werden Objekte und Hindernisse erkennbar und
kann diese somit ausweichen.

Die Videoübertragung wird über der ganzen Website im Hintergrund angezeigt.

Im HTML-Code wird die Videoübertragung als HTML <img>-Tag mit der id dynamicimage
im Hauptbereich definiert.

Daniel Schauer - nur als Muster  18
Im CSS-Code wird nun das Element mit der id dynamicimage formatiert. Es wird defi-
niert, dass die Größe 100% der Breite sowie 100% der Höhe einnimmt. Die Position wird
dabei auf absolut gesetzt.

Im JavaScript-Code wird die WebSocket-Verbindung zur ESP32-CAM gehandelt. In der
Funktion connectWebSocket_cam() wird zuerst ein WebSocket mit der eigenen IP-
Adresse erstellt (da Webserver auf ESP32-CAM gehostet wird) und dem Port 81 erstellt.
Wenn nun eine Nachricht auf der WebSockte-Verbindung ankommt (siehe Videoübertra-
gung ESP32-CAM) wird diese extrahiert. Das mitgesendete BLOB wird in einem neuem
BLOB als jpeg-Bild gespeichert. Danach wird eine URL (Adresse) erstellt, die zu diesem
BLOB führt. Dann wird eine Variable für die Videoübertragung im HTML <img>-Tag
erstellt. Die Source dieses Bildes wird dann mit dem neuen, erhaltenen Bild ersetzt. Da
die ESP32-CAM die ganze Zeit neue Blobs sendet, wird das Bild die ganze Zeit ersetzt,
was dazu führt, dass es aussieht, als wäre es ein Video.

Wenn sich die ESP32-CAM verbindet, wird zu Debug-Zwecken eine Nachricht in der
Webkonsole ausgegeben.

Wenn die Verbindung zur ESP32-CAM verloren geht, wird wieder zu Debug-Zwecke ei-
ne Nachricht in der Webkonsole ausgegeben und ein neuer Verbindungsversuch wird nach
5 Sekunden gestartet.

4.7.3 Anzeige von Sensordaten und Verbindungsstatus

Sensordaten

In der linken oberen Ecke der Website befindet sich das Menü-icon. Ein Klick darauf ruft
die Sidebar für die Daten auf. Die Sidebar klappt sich am linken Bildschirmrand auf. Dar-
in kann ist der aktuelle Akkustand sowie das aktuelle aufliegende Gewicht auslesbar. Um
das Menü wieder schließen zu können, ist ein erneuter Klick auf das Icon erforderlich und
die Sidebar wird wieder zugeklappt.

Im HTML-Code wird im Body-Bereich wird das Icon als HTML <img>-Tag eingefügt.
Als Quelle wird die im SPIFFS hochgeladene Grafik menu-icon.svg Grafik verwendet.
Für das Design wird die CSS-Klasse menu-icon verwendet und beim onclick Event wird
die JavaScript Funktion togglemenu() aufgerufen.

Im HTML <div>-Tag werden die einzelnen Daten festgelegt und mir der CSS-Klasse

Daniel Schauer - nur als Muster  19
mymenu formatiert. Das Gewicht und der Akkustand werden als HTML <p>-Tag ange-
zeigt und mit der CSS-Klasse daten formatiert.

In der CSS-Klasse mymenu wird die sidebar formatiert. Das Menü ist fixiert und nimmt
100% der Höhe ein. Die Anfängliche ist 0, da es versteckt bzw. eingeklappt ist. Die Hin-
tergrundfarbe ist schwarz und es befindet sich auf der z-Ebene 1 um den Hauptinhalt
überdecken zu können. Beim Ein- und Ausblenden dauert 0.5 Sekunden, um einen sanf-
ten Übergang zu ermöglichen.

Der Hautinhalt #main hat eine Animation, damit er beim Öffnen des Menüs nach rechts
verschoben werden kann.

Falls der Bildschirm kleiner als 450px Höhe hat, werden die Abstände der angezeigten
Daten verkleinert. Das dient dazu, um besonders auf Handys die Ansicht zu optimieren.

Die CSS-Klasse menu-icon positioniert das Icon in der linken oberen Ecke mit einer
30x30px Format. Cursor: pointer sorgt dafür, dass das Icon anklickbar ist.

Die CSS-Klasse daten formatiert die einzelnen Daten im Menü. Sie werden in der Schrift-
art Arial, Helvetica oder sans-serif angezeigt und in der Farbe Weiß, mit der Schriftgröße
1.2em (20% größer) mittig angezeigt.

In der JavaScript Funktion connectWebSocket_carybot() wird im onmessage()-event
die übertragenen Daten verarbeitet. Für debug-Zwecken werden die angekommen Da-
ten in der WebKonsole ausgegeben. Danach werden die JSON-Nachrichten extrahiert.
Wenn die Nachricht den Akkustand beinhaltet, wird dieser im HTML <p>-Tag mit der id
Akkustand im Menü angezeigt. Wenn die Nachricht das Gewicht beinhaltet, wird dieses
im HTML <p>-Tag mit der id Gewicht im Menü angezeigt. Falls beim Umwandeln ein
Fehler auftreten sollte, wird dieser in der Webkonsole ausgegeben.

Verbindungsstatus

In der WebSocket Status-Box wird der aktuelle Verbindungszustand zum ESP32 ange-
zeigt. Wenn keine Verbindung vorhanden ist, ist die Box rot. Wenn die Verbindung er-
folgt, wird die Box grün.

Im HTML-Code wird die Status-Box als HTML <span>-Tag definiert. Für das Design
wird die CSS-Klasse status-box kombiniert je nach Verbindungsstatus mit der Klasse

Daniel Schauer - nur als Muster  20
connected oder disconnected.

In der CSS-Klasse status-box wird die grundlegende Box am linken oberen Bildschirm-
rand positioniert. Die Box liegt auf der zweiten z-Ebene. Die Schrift wird weiß defi-
niert und wird fett dargestellt. Wenn eine Verbindung hergestellt wurde, wird der Hinter-
grund auf grün festgelegt (status-box.connected), ansonsten ist der Hintergrund rot
(status-box.disconnected).

Im JavaScript-Code werden die onopen() und onclose() Events der WebSocket Ver-
bindung gehandelt. Bei einem Verbindungsaufbau (onopen()) wird die Status-Box grün
und der Text wechselt zu Connected. Außerdem wird eine Nachricht für Debug-Zwecke
ausgegeben. Bei einem Verbindungsabbruch wird die Status-Box wieder rot und der Text
wechselt zu Disconnected. Es wird automatisch alle 5 Sekunden ein neuer Versuch zur
Verbindungsaufbau gestartet.

4.8 Herausforderungen und Optimierungen

4.8.1 Probleme bei der WebSocket Kommunikation

4.8.2 Latenz- und Performance Optimierungen

4.8.3 (Speicher- und Rechenleistungseinschränkungen des ESP32)

Daniel Schauer - nur als Muster  15
4.9 (Fazit und Ausblick)

4.9.1 (Mögliche Erweiterungen und Verbesserungen)

5 Gehäuse

5.1 Planung und Design
5.2 Realisierung
5.3 Materialliste

6 Platine

6.1 Grundschaltung
6.2 Circuit Board
6.3 Fertiger Prototyp

7 Kamera

7.1 Kamera im Überblick
7.2 Videoübertragung
7.3 Kameraschwenkung

7.3.1 Gehäuse
7.3.2 Servomotor

7.4 Code

Daniel Schauer - nur als Muster                    16
8 Sensoren

8.1 Abstandsensor

8.2 Gewichtsmessung

8.2.1 Grundprinzip
8.2.2 Schaltungsaufbau
8.2.3 Code

9 Entwicklungstools

9.1 Autodesk Fushion

9.2 Eagle

9.3 VS-Code

Visual Studio Code (VS-Code) ist eine kostenlose IDE (integrated development environ-
ment) entwickelt von Microsoft. VS-Code funktioniert auch auf anderen Betriebssyste-
men wie zum Beispiel Windows, Linux oder macOS. VS-Code unterstützt einen Großteil
der Programmiersprachen und kann durch Extentions mit vielen nützlichen Features und
Sprachen immer wieder erweitert werden.2

9.3.1 Setup
Um ein Projekt in VS-Code erstellen zu können, müssen einige Schritte befolgt werden.
Zuallererst muss die IDE von https://code.visualstudio.com/ für das jeweilig passende Be-
triebssystem heruntergeladen und installiert werden. Um Mikrocontroller wie ESPs oder
Arduinos in VS-Code programmieren zu können, wird die PlatformIO IDE Extension be-
nötigt. Um die PlatformIO IDE Extension in VS-Code zu installieren, drückt man einfach
auf das Extensions Symbol oder drückt die Tastenkombination Ctrl+Shift+X um das Ex-
tensions Menü zu öffnen. Danach gibt man in der Suchleiste “PlatformIO IDE“ ein und
wählt die Extension mit der Ameise als Icon. Dann drückt man auf “Install“ und wartet,
bis die Extension fertig heruntergeladen ist. Nach der Installation sollte das PlatformIO
Icon (Ameisenkopf) auf der linken Seite unter dem Extension Menü erscheinen.

    2https://code.visualstudio.com/

Daniel Schauer - nur als Muster  17
Um nun ein neues Projekt zu erstellen, klickt man auf das PlatformIO Icon und wählt “+
New Project“.

Im Project Wizard wählt man nun den gewünschten Namen, das Board, das Framework
als auch den Speicherungsort des Projektes. Bei unserem Projekt wählten wir das Board
“Espressif ESP32 Dev Module“ und als Framework “Arduino“, da wir einen EPS32 zum
Programmieren verwendeten.

9.3.2 Bibliotheken

Bibliotheken sind ein weiterer wichtiger Bestandteil für das Programmieren. Bibliotheken
beinhalten bereits eine Sammlung von vorgefertigtem Code, der für bestimmte Aufgaben,
wie zum Beispiel zum Auswerten eines Sensors, verwendet werden kann. Bibliotheken
werden verwendet, um den Code zu minimieren und dadurch die Lesbarkeit sowie die
Effizienz zu steigern. Um eine Bibliothek für PlatformIO in VS-Code zu installieren, muss
das PIO Home Menü geöffnet werden. Darin befindet sich der Reiter „Libraries“. Wenn
dieses geöffnet wird, erscheint eine Suchleiste, mit der die gewünschten Bibliotheken zum
Projekt hinzugefügt werden können.

9.3.3 verwendete Bibliotheken

ESPAsyncWebServer

Die ESPAsnycWebServer Bibliothek ermöglicht es, Webanwendungen effizient und mit
hoher Performance auf ESP8266- und ESP32 Mikrocontroller zu hosten. Der Asynchro-
ne Betrieb verhindert Blockierungen und sorgt für eine flüssige Verarbeitung mehrere
Anfragen gleichzeitig. Außerdem unterstützt die Bibliothek WebSockets, welche für die
Echtzeitkommunikation zwischen Client und Server benötigt wurden. Die Bibliothek ist
eine leistungsfähigere Alternative zur klassischen WebServer-Bibliothek, da sie ressour-
censchonender und nicht blockieren arbeitet.3

ArduinoJSON

Die ArduinoJson Bibliothek ermöglicht die Verarbeitung von JSON-String in Objekte
und umgekehrt. Sie ist speziell für Geräte mit begrenztem Speicher und Rechenleistung
optimiert. Die Bibliothek wird benötigt, um die erhaltenen Steuerbefehle am ESp32 zu
konvertieren und um sie anschließend weiterzuverarbeiten.4

    3https://github.com/lacamera/ESPAsyncWebServer
    4https://arduinojson.org/

Daniel Schauer - nur als Muster  18
HCSR04
arduinoWebSockets
Die WebSockets Bibliothek ermöglicht eine Kommunikation über das WebSocket Pro-
tokoll für Arduino-Boards, ESP8266 und ESP32. Die Bibliothek wird für die Echtzeit-
Kommunikation zwischen dem Webserver und den ESP32 benötigt. Außerdem werden
die Bilder der ESp32-CAM über einen WebSocket an den Webserver gesendet. Die Bi-
bliothek ist eine großartige Ergänzung zur ESPAsyncWebServer Bibliothek.5

ESp32Servo
Adafruit_MCP23x17
HX711_ADC

9.4 LaTex
9.5 GitHub

10 Abbildungsverzeichnis

Abbildungsverzeichnis

    1 Porträt Daniel Schauer . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
    2 Porträt Simon Spari . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
    3 Porträt Felix Hochegger . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
    4 SPIFFS Initalisierung . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23

11 Literaturverzeichnis

5https://github.com/Links2004/arduinoWebSockets

Daniel Schauer - nur als Muster                  19

